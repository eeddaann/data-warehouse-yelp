{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review's Stars Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Naïve Bayes algorithm will be used for the prediction. \n",
    "This algorithem assumes independence between the features, so the chosen features are independent as possible.\n",
    "The chosen features are:\n",
    "\n",
    "* **sentimemt & magnitude** Classified before using Naïve Bayes classifier, the reviews classified into 3 classes: positive, negative and neutral. The magnitude is the indicator for the significance of the sentiment.\n",
    "\n",
    "* **user's stars** The average stars of previous reviews from a given user. Based on *\"The rich get richer and the poor get poorer\"* a user who wrote good reviews in the past has good chance to write good review this time.    \n",
    "\n",
    "* **business' stars** The average stars of previous reviews for a given business. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare the data\n",
    "\n",
    "\n",
    "The view with the relevant columns created with:\n",
    "\n",
    "```SQL\n",
    "Create view dataset as \n",
    "(SELECT f.review_id as id,f.sentimemt as sentiment,f.magnitude as magnitude,\n",
    "u.average_stars as u_stars,b.b_stars as b_stars,f.r_stars as r_stars\n",
    "FROM fact_table f\n",
    "LEFT JOIN users as u\n",
    "ON f.user_id = u.user_id\n",
    "LEFT JOIN business as b\n",
    "ON f.business_id = b.business_id);\n",
    "```\n",
    "\n",
    "Than the dataset splited into training_set and test_set, ratio 80/20:\n",
    "\n",
    "```SQL\n",
    "\n",
    "Create view training_set as \n",
    "(SELECT *\n",
    " FROM dataset\n",
    " ORDER BY id ASC\n",
    " LIMIT 143819);\n",
    " \n",
    " Create view test_set as \n",
    "(SELECT *\n",
    " FROM dataset\n",
    " ORDER BY id DESC\n",
    " LIMIT 35954);\n",
    "\n",
    "\n",
    "```\n",
    "**note: review_id column is encrypted, this fact helped to shuffle the dataset.** \n",
    "\n",
    "## likelihood calculation\n",
    "\n",
    "The model based on the following equation:\n",
    "$$\n",
    "p(c|X)=p(x_{sentimemt}|c)*p(x_{user}|c)*p(x_{business}|c)*p(c)\n",
    "$$\n",
    "\n",
    "Where p(c|X) is the posterior probability of class (number of stars) given predictor (set of features X).\n",
    "The class with the highest probability will be the prediction for the given review.\n",
    "\n",
    "in the following blocks we present the queries we used to extract the likelihood probabilities of each feature.\n",
    "each query saves the results in csv file and than pandas' dataframes used to manupulate the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import operator\n",
    "import tqdm\n",
    "import os.path\n",
    "if os.path.isfile(\"user.csv\"):\n",
    "    path=\"\"\n",
    "else:\n",
    "    #mysql's default env\n",
    "    path=\"C:\\ProgramData\\MySQL\\MySQL Server 5.7\"  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### user stars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```SQL\n",
    "SELECT ROUND(u_stars, 0) AS u,ROUND(r_stars, 0) AS r, COUNT(*) AS COUNT\n",
    "FROM   dev_local.training_set\n",
    "GROUP  BY u,r\n",
    "INTO OUTFILE 'C:/ProgramData/MySQL/MySQL Server 5.7/Uploads/user.csv'\n",
    "FIELDS TERMINATED BY ',';\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>u_stars</th>\n",
       "      <th>r_stars</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.020943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   u_stars  r_stars      prob\n",
       "0        1        1  0.020943\n",
       "1        1        2  0.000633\n",
       "2        1        3  0.000035\n",
       "3        1        4  0.000014\n",
       "4        1        5  0.000042"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_prob = pd.read_csv(path+'\\Uploads\\user.csv',\\\n",
    "names=['u_stars', 'r_stars', 'prob'])\n",
    "# normalization to get probability\n",
    "user_prob[\"prob\"]=user_prob[\"prob\"]/float(user_prob[\"prob\"].sum()) \n",
    "user_prob.head()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### business stars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```SQL\n",
    "SELECT ROUND(b_stars, 0) AS b,ROUND(r_stars, 0) AS r, COUNT(*) AS COUNT\n",
    "FROM   dev_local.training_set\n",
    "GROUP  BY b,r\n",
    "INTO OUTFILE 'C:/ProgramData/MySQL/MySQL Server 5.7/Uploads/business.csv'\n",
    "FIELDS TERMINATED BY ',';\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b_stars</th>\n",
       "      <th>r_stars</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   b_stars  r_stars      prob\n",
       "0        1        1  0.002955\n",
       "1        1        2  0.000167\n",
       "2        1        3  0.000014\n",
       "3        1        4  0.000007\n",
       "4        1        5  0.000007"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bus_prob = pd.read_csv(path+'\\Uploads\\\\business.csv',\\\n",
    "names=['b_stars', 'r_stars', 'prob'])\n",
    "# normalization to get probability\n",
    "bus_prob[\"prob\"]=bus_prob[\"prob\"]/float(bus_prob[\"prob\"].sum()) \n",
    "bus_prob.head()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sentiment and magnitude \n",
    "\n",
    "```SQL\n",
    "SELECT (sentiment) AS sent,ROUND(magnitude, 1) AS mag,ROUND(r_stars, 0) AS r, COUNT(*) AS COUNT\n",
    "FROM   dev_local.training_set\n",
    "GROUP  BY sent,mag,r\n",
    "INTO OUTFILE 'C:/ProgramData/MySQL/MySQL Server 5.7/Uploads/sentiment_magnitude.csv'\n",
    "FIELDS TERMINATED BY ',';\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>magnitude</th>\n",
       "      <th>r_stars</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>na</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>na</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>na</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.002559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>na</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.006119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>na</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.007078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment  magnitude  r_stars      prob\n",
       "0        na        0.0        1  0.001613\n",
       "1        na        0.0        2  0.001592\n",
       "2        na        0.0        3  0.002559\n",
       "3        na        0.0        4  0.006119\n",
       "4        na        0.0        5  0.007078"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_mag_prob = pd.read_csv(path+'\\Uploads\\sentiment_magnitude.csv', \\\n",
    "names=['sentiment', 'magnitude', 'r_stars', 'prob'])\n",
    "sent_mag_prob[\"prob\"]=sent_mag_prob[\"prob\"]/float(sent_mag_prob[\"prob\"].sum())\n",
    "sent_mag_prob.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prior probability of class\n",
    "```SQL\n",
    "SELECT ROUND(r_stars, 0) AS r, COUNT(*) AS COUNT\n",
    "FROM   dev_local.training_set\n",
    "GROUP  BY r\n",
    "INTO OUTFILE 'C:/ProgramData/MySQL/MySQL Server 5.7/Uploads/prior.csv'\n",
    "FIELDS TERMINATED BY ',';\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r_stars</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.110743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.093242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.137409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.279796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.378809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   r_stars      prob\n",
       "0        1  0.110743\n",
       "1        2  0.093242\n",
       "2        3  0.137409\n",
       "3        4  0.279796\n",
       "4        5  0.378809"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prior_prob = pd.read_csv(path+'\\Uploads\\prior.csv',names=['r_stars', 'prob'])\n",
    " # normalization to get probability\n",
    "prior_prob[\"prob\"]=prior_prob[\"prob\"]/float(prior_prob[\"prob\"].sum())\n",
    "prior_prob.head()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load test set\n",
    "```SQL\n",
    "SELECT *\n",
    "FROM   dev_local.test_set\n",
    "INTO OUTFILE 'C:/ProgramData/MySQL/MySQL Server 5.7/Uploads/test.csv'\n",
    "FIELDS TERMINATED BY ',';\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>magnitude</th>\n",
       "      <th>u_stars</th>\n",
       "      <th>b_stars</th>\n",
       "      <th>r_stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>___iDWC9iXf9R6BtxXgNcQ</td>\n",
       "      <td>pos</td>\n",
       "      <td>0.470707</td>\n",
       "      <td>2.86</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>___6FK0UHRSWL3kpUvCaEQ</td>\n",
       "      <td>pos</td>\n",
       "      <td>0.089197</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>__zNo9PDQytR7MTcMd4QQw</td>\n",
       "      <td>neg</td>\n",
       "      <td>0.490903</td>\n",
       "      <td>3.85</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>__yGuzTDg1gWWptrRLPxsQ</td>\n",
       "      <td>pos</td>\n",
       "      <td>0.298717</td>\n",
       "      <td>4.33</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>__XTzfeXw2Bw42-vFDJkRQ</td>\n",
       "      <td>neg</td>\n",
       "      <td>0.232015</td>\n",
       "      <td>4.13</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id sentiment  magnitude  u_stars  b_stars  r_stars\n",
       "0  ___iDWC9iXf9R6BtxXgNcQ       pos   0.470707     2.86      4.5        5\n",
       "1  ___6FK0UHRSWL3kpUvCaEQ       pos   0.089197     1.00      1.5        1\n",
       "2  __zNo9PDQytR7MTcMd4QQw       neg   0.490903     3.85      4.0        4\n",
       "3  __yGuzTDg1gWWptrRLPxsQ       pos   0.298717     4.33      4.0        4\n",
       "4  __XTzfeXw2Bw42-vFDJkRQ       neg   0.232015     4.13      4.5        4"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(path+'\\Uploads\\\\test.csv',\\\n",
    "names=['id','sentiment','magnitude','u_stars','b_stars', 'r_stars'])\n",
    "test.head()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict(x):\n",
    "    # get feature vector x and returns the predicted number of stars\n",
    "    p_x_c={}\n",
    "    for stars in range(1,6):\n",
    "        #user's stars feature\n",
    "        p_x_c[stars]=user_prob.query('r_stars == %s & u_stars == %s'\\\n",
    "        %(stars,x[0])).iloc[0]['prob']\n",
    "        #business's stars feature\n",
    "        p_x_c[stars]*=bus_prob.query('r_stars == %s & b_stars == %s'\\\n",
    "        %(stars,x[1])).iloc[0]['prob']\n",
    "        #sentiment & magnitude feature\n",
    "        p_x_c[stars]*=sent_mag_prob.query('r_stars == %s & sentiment == \"%s\" & magnitude==%s'\\\n",
    "        %(stars,x[2],x[3])).iloc[0]['prob']\n",
    "        #multiply with the prior p(c)\n",
    "        p_x_c[stars]*=prior_prob.iloc[stars-1]['prob']\n",
    "    #returns the key (num of stars) which associated to the highest probability \n",
    "    return (max(p_x_c.iteritems(), key=operator.itemgetter(1))[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "35954it [20:19, 29.48it/s]\n"
     ]
    }
   ],
   "source": [
    "counter=0\n",
    "for index, row in tqdm.tqdm(test.iterrows()):\n",
    "    x=[int(row['u_stars']), int(row['b_stars']),row[\"sentiment\"],round(row[\"magnitude\"],1)]\n",
    "    if predict(x)==row[\"r_stars\"]:\n",
    "        counter+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 41.8%\n"
     ]
    }
   ],
   "source": [
    "print ('accuracy: {}%'.format(round(float(counter)/35954,3)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One hypothesis for the results are the business' stars which may seem unrelated for a given review, so a proposed model was to ignore this feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_without_bus(x):\n",
    "    # get feature vector x and returns the predicted number of stars\n",
    "    p_x_c={}\n",
    "    for stars in range(1,6):\n",
    "        #user's stars feature\n",
    "        p_x_c[stars]=user_prob.query('r_stars == %s & u_stars == %s'%(stars,x[0])).iloc[0]['prob']\n",
    "        #sentiment & magnitude feature\n",
    "        p_x_c[stars]*=sent_mag_prob.query('r_stars == %s & sentiment == \"%s\" & magnitude==%s'\\\n",
    "        %(stars,x[2],x[3])).iloc[0]['prob']\n",
    "        #multiply with the prior p(c)\n",
    "        p_x_c[stars]*=prior_prob.iloc[stars-1]['prob']\n",
    "    #returns the key (num of stars) which associated to the highest probability \n",
    "    return (max(p_x_c.iteritems(), key=operator.itemgetter(1))[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "35954it [14:08, 42.39it/s]\n"
     ]
    }
   ],
   "source": [
    "counter_without_bus=0\n",
    "for index, row in tqdm.tqdm(test.iterrows()):\n",
    "    x=[int(row['u_stars']), int(row['b_stars']),row[\"sentiment\"],round(row[\"magnitude\"],1)]\n",
    "    if predict_without_bus(x)==row[\"r_stars\"]:\n",
    "        counter_without_bus+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 40.5%\n"
     ]
    }
   ],
   "source": [
    "print ('accuracy: {}%'.format(round(float(counter_without_bus)/35954,3)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the results got worse.\n",
    "than, prediction only by user's stars inspected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_by_user(x):\n",
    "    # get feature vector x and returns the predicted number of stars\n",
    "    p_x_c={}\n",
    "    for stars in range(1,6):\n",
    "        #user's stars feature\n",
    "        p_x_c[stars]=user_prob.query('r_stars == %s & u_stars == %s'\\\n",
    "        %(stars,x[0])).iloc[0]['prob']\n",
    "        #multiply with the prior p(c)\n",
    "        p_x_c[stars]*=prior_prob.iloc[stars-1]['prob']\n",
    "    #returns the key (num of stars) which associated to the highest probability \n",
    "    return (max(p_x_c.iteritems(), key=operator.itemgetter(1))[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "35954it [06:28, 92.47it/s]\n"
     ]
    }
   ],
   "source": [
    "counter_by_user=0\n",
    "for index, row in tqdm.tqdm(test.iterrows()):\n",
    "    x=[int(row['u_stars']), int(row['b_stars']),row[\"sentiment\"],round(row[\"magnitude\"],1)]\n",
    "    if predict_by_user(x)==row[\"r_stars\"]:\n",
    "        counter_by_user+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 41.6%\n"
     ]
    }
   ],
   "source": [
    "print ('accuracy: {}%'.format(round(float(counter_by_user)/35954,3)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the result is very close to the full model but each prediction took only 0.01 seconds - three times faster!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## conclusion\n",
    "\n",
    "To sum up, a Naïve Bayes algorithm proposed to predict the star raiting of a given review.\n",
    "The model succeed to predict about 40% of the test set. Although it sounds like a poor result, it is 2 times better than a random predictor. In addition, prediction of a given review takes about 0.001 seconds which is pretty fast.\n",
    "To imporove preformance we suggest the following steps:\n",
    "\n",
    "* look for better features - As diffrent features experimented the final model is based only on the previous reviews of the user. More features may improve accuracy if they will be picked wisely.  \n",
    "\n",
    "\n",
    "* optimize the prediction function - As noted, the more features the more time each iteration takes. maybe there is a faster implemention of this function using matrix multipication"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
