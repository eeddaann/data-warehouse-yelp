{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DW PROJECT - PART A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "#Authors: Lital Hendizadeh, Edan Shahmoon and Shai Ardazi\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import petl as etl\n",
    "import MySQLdb as mdb\n",
    "import csv\n",
    "from datetime import timedelta, date\n",
    "import holidays\n",
    "import calendar\n",
    "import nltk.classify.util\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.corpus import movie_reviews\n",
    "from nltk.corpus import stopwords\n",
    "import pickle\n",
    "import os.path\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Words classification may take a lot of time. Please change variable \"debug\" to False only when necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##########################\n",
    "debug=True\n",
    "##########################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract - Reading from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "business_json = etl.fromjson('yelp_academic_dataset_business_PA.json')\n",
    "users_json = etl.fromjson('yelp_academic_dataset_users_nofriendlist_PA.json')\n",
    "reviews_json_facts = etl.fromjson('yelp_academic_dataset_review_drop_PA.json')\n",
    "full_reviews_good=etl.fromcsv('Pittsburgh_full_reviews_text.csv',encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform - Types convertions functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#Convertion functions\n",
    "def to_string(text):\n",
    "    return str(text)\n",
    "def to_float(text):\n",
    "    return float(text)\n",
    "def to_int(text):\n",
    "    return int(text)\n",
    "def to_boolean(text):\n",
    "    if text ==\"True\":\n",
    "        return True\n",
    "    if text == \"False\":\n",
    "        return False\n",
    "\n",
    "  \n",
    "def to_list (text):\n",
    "    if text[0]=='[' and text[-1]==']':\n",
    "        items = text[2:-1].split(', u') # turn values to list\n",
    "    else:\n",
    "        return None\n",
    "    for i in range(len(items)):\n",
    "        items[i]=items[i][1:-1]\n",
    "    return items\n",
    "def to_date (text):\n",
    "    return datetime.strptime(text, '%Y-%m-%d')\n",
    "\n",
    "#Functions that call the convertions functions\n",
    "def converting_to_str(val,name_of_tbl1):\n",
    "    return name_of_tbl1.convert(val,to_string)\n",
    "def converting_to_int(val,name_of_tbl1):\n",
    "    return name_of_tbl1.convert(val,to_int)\n",
    "def converting_to_float(val,name_of_tbl1):\n",
    "    return name_of_tbl1.convert(val,to_float)\n",
    "def converting_to_list(val,name_of_tbl1):\n",
    "    return name_of_tbl1.convert(val,to_list)\n",
    "def converting_to_date(val,name_of_tbl1):\n",
    "    return name_of_tbl1.convert(val,to_date)\n",
    "def converting_to_boolean(val,name_of_tbl1):\n",
    "    return name_of_tbl1.convert(val,to_boolean) \n",
    "\n",
    "\n",
    "def to_dict(text):\n",
    "    if text[0]=='[' and text[-1]==']':\n",
    "        items = text[1:-1].split(', ') # turn values to list\n",
    "    else:\n",
    "        return None\n",
    "    output = {}\n",
    "    for i in items:\n",
    "        key, value = i.split(':') # splitting to key and value\n",
    "        output[key]=int(value)\n",
    "    return items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fields calculation functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#global variables required for the tables' ids creation\n",
    "global_user_id=0\n",
    "global_bussiness_id2=0\n",
    "global_review_id=0\n",
    "global_date_id=0\n",
    "\n",
    "#Creating ids for tables\n",
    "def bussiness_id_generator (row):\n",
    "    global global_bussiness_id2\n",
    "    global_bussiness_id2+=1\n",
    "    return global_bussiness_id2\n",
    "\n",
    "def date_id_generator (row):\n",
    "    global global_date_id\n",
    "    global_date_id+=1\n",
    "    return global_date_id\n",
    "\n",
    "\n",
    "def user_id_generator (row):\n",
    "    global global_user_id\n",
    "    global_user_id+=1\n",
    "    return global_user_id\n",
    "\n",
    "def more_than_20 (row):#checking if a business has more than 20 reviews since 20 is the limit for reviews in a business page\n",
    "    if row['review_count']>20:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "#user table\n",
    "\n",
    "def active_years (row):#user's active years\n",
    "    yelping_start_year=row[\"yelping_since\"].year\n",
    "    #cur_year = datetime.datetime.now.year\n",
    "    cur_year=2017\n",
    "    return cur_year-yelping_start_year\n",
    "\n",
    "def funny_average(row):\n",
    "    if row['review_count']==0:\n",
    "        return 0\n",
    "    return float(row['funny'])/row['review_count']\n",
    "\n",
    "def cool_average(row):\n",
    "    if row['review_count']==0:\n",
    "        return 0\n",
    "    return float(row['cool'])/row['review_count']\n",
    "\n",
    "def fans_average (row):\n",
    "    if row[\"fans\"]==0:\n",
    "        return 0\n",
    "    return row[\"fans\"]/float(row[\"review_count\"])\n",
    "\n",
    "def useful_average(row):\n",
    "    if row['review_count']==0:\n",
    "        return 0\n",
    "    return float(row['useful'])/row['review_count']\n",
    "\n",
    "def weighted_score_for_reviews (row):\n",
    "    useful=row[\"useful\"]\n",
    "    funny=row[\"funny\"]\n",
    "    cool=row[\"cool\"]\n",
    "    weighted_mean=(0.5*useful+0.25*(funny+cool))/float(12)\n",
    "    return weighted_mean\n",
    "\n",
    "def yelp_celebrity (row):#Based on pre calculations on our data only- there are several hundrenrds users who have more than 50 followers\n",
    "    return row[\"fans\"]>50\n",
    "\n",
    "def loveliness_level (row):\n",
    "    avg_stars=row['average_stars']\n",
    "    if avg_stars<1.5:\n",
    "        return \"1\" #disgrading user\n",
    "    elif 1.5<avg_stars<3.5:\n",
    "        return \"2\"#average user\n",
    "    return\"3\"#a giver user\n",
    "\n",
    "def active_user (row):\n",
    "    return row[\"review_count\"]>1000\n",
    "\n",
    "def elite_first_year_func (row):\n",
    "    elite_first_year=min(row[\"elite\"])\n",
    "    return elite_first_year\n",
    "\n",
    "def elite_counter_func (row):\n",
    "    return len(row[\"elite\"])\n",
    "\n",
    "def is_elite_gold_func (row):\n",
    "    if len(row['elite'])>5:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def is_elite_black_func (row):\n",
    "    if len(row['elite'])>10:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def num_of_compliment_func (row):\n",
    "    sum_com= row[\"compliment_cute\"]+row[\"compliment_writer\"]+row[\"compliment_note\"]+row[\"compliment_cool\"]+row[\"compliment_profile\"]+row[\"compliment_hot\"]+row[\"compliment_more\"]+row[\"compliment_plain\"]+row[\"compliment_funny\"]+row[\"compliment_list\"]+row[\"compliment_photos\"]\n",
    "    return sum_com\n",
    "\n",
    "def time_to_elite_func (row):\n",
    "    elite_first_year=row[\"elite_first_year\"]\n",
    "    if elite_first_year == \"None\" :\n",
    "      return -1\n",
    "    elite_first_year=int (row[\"elite_first_year\"])\n",
    "    yelping_start_year=row[\"yelping_since\"].year\n",
    "    ans=elite_first_year-yelping_start_year\n",
    "    return ans\n",
    "\n",
    "def elite_sequence(row):\n",
    "    return 999\n",
    "\n",
    "#fact table\n",
    "\n",
    "def review_id_generator(row):\n",
    "    global global_review_id\n",
    "    global_review_id+=1\n",
    "    return global_review_id\n",
    "\n",
    "def ratio_funny_review_user(row):\n",
    "    if row[\"funny_average\"] == 0:  \n",
    "        return 0\n",
    "    return float(row['funny']) / row[\"funny_average\"]\n",
    "\n",
    "def ratio_cool_review_user(row):\n",
    "    if row[\"cool_average\"] == 0:  \n",
    "        return 0\n",
    "    return float(row['cool']) / row[\"cool_average\"]\n",
    "\n",
    "def ratio_useful_review_user(row):\n",
    "    if row[\"useful_average\"] == 0:  \n",
    "        return 0\n",
    "    return float(row['useful']) / row[\"useful_average\"]\n",
    "\n",
    "def ratio_funny_reactios(row):\n",
    "    if row[\"funny\"] == 0:  \n",
    "        return 0\n",
    "    return float(row['funny']) / (row[\"funny\"]+row['cool']+row['useful'])\n",
    "\n",
    "def ratio_cool_reactios(row):\n",
    "    if row[\"cool\"] == 0:  \n",
    "        return 0\n",
    "    return float(row['cool']) / (row[\"funny\"]+row['cool']+row['useful'])\n",
    "def ratio_useful_reactios(row):\n",
    "    if row[\"useful\"] == 0:  \n",
    "        return 0\n",
    "    return float(row['useful']) / (row[\"funny\"]+row['cool']+row['useful'])\n",
    "\n",
    "def distance_stars_user(row): \n",
    "    return float(row['r_stars'])-float(row['average_stars'])\n",
    "\n",
    "def distance_stars_business(row): \n",
    "    return float(row['r_stars'])-float(row['b_stars'])\n",
    "\n",
    "def sentimemt_func(row):\n",
    "    return classify(row[\"text\"])[1]\n",
    "\n",
    "def folaritey_func(row):\n",
    "    return classify(row[\"text\"])[2]\n",
    "def num_of_words_in_review_func(row):\n",
    "    if row[\"text\"]==None:\n",
    "        return 0\n",
    "    return len(row[\"text\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creat Date Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def daterange(start_date, end_date):\n",
    "    for n in range(int ((end_date - start_date).days)):\n",
    "        yield start_date + timedelta(n)\n",
    "#these dates were chosen in order to be able to have all existing dates indexed in our dates table.\n",
    "start_date = date(2004, 1, 1)\n",
    "end_date = date(2018, 6, 2)\n",
    "dates=[['date_id','full_date','day','day_name','month','month_name','year','is_weekend','is_holiday','holiday_name']]\n",
    "us_holidays = holidays.UnitedStates()\n",
    "month_lst=[0,'January','February','March','April','May','June','July','August','September','October','November','December']\n",
    "date_id=0\n",
    "\n",
    "for single_date in daterange(start_date, end_date):\n",
    "    date_id+=1\n",
    "    full_date=single_date\n",
    "    year=full_date.year\n",
    "    month=full_date.month\n",
    "    day=full_date.day\n",
    "    is_holiday=full_date in us_holidays\n",
    "    holiday_name=us_holidays.get(full_date)\n",
    "    day_name=calendar.day_name[calendar.weekday(year, month, day)]\n",
    "    month_name = month_name = month_lst[month]\n",
    "    is_weekend=day_name in ['Saturday','Sunday']\n",
    "    \n",
    "    dates.append([date_id,full_date,day,day_name,month,month_name,year,is_weekend,is_holiday,holiday_name])\n",
    "with open('dates_dim.csv', 'wb') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(dates)\n",
    "dates_dim = etl.fromcsv('dates_dim.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting fields to required types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def types_convertion(business_json1,users_json1,reviews_json_facts1,full_reviews,dates_dim1):\n",
    "    counter=0\n",
    "    f_to_str_b=[\"city\",\"name\",\"state\",\"address\",\"business_id\"]#columns in business table  we convert to str\n",
    "    f_to_float_b=[\"stars\"]#column in business table we convert to boolean\n",
    "    f_to_list_b=[\"categories\",\"hours\",\"attributes\"]#columns in business table we convert to lists\n",
    "    f_to_str_u=[\"user_id\",\"name\",\"yelping_since\"]#columns in users table we convet to string\n",
    "    f_to_str_facts=[\"user_id\",\"review_id\",\"business_id\",\"date\"]#columns in fact table we convert to string\n",
    "    full_review_to_str=[\"review_id\",\"text\"]#columns in full reviews table we convert to string\n",
    "    d_to_str=[\"day_name\",\"month_name\",\"holiday_name\"]#columns in dates table we convert to string\n",
    "    d_to_int=[\"date_id\",\"day\",\"month\",\"year\"]#columns in dates table we convert to integer\n",
    "    d_to_bool=[\"is_weekend\",\"is_holiday\"]#columns in dates table we convert to boolean\n",
    "    \n",
    "    #converting to required types\n",
    "    for field in f_to_str_b:\n",
    "        f=field\n",
    "        business_json1=converting_to_str(f,business_json1)\n",
    "    for field in f_to_float_b:\n",
    "        f=field\n",
    "        business_json1=converting_to_float(f,business_json1)\n",
    "    for field in f_to_list_b:\n",
    "        f=field\n",
    "        business_json1=converting_to_list(f,business_json1)\n",
    "    for field in f_to_str_u:\n",
    "        f=field\n",
    "        users_json1=converting_to_str(f,users_json1)\n",
    "    for field in f_to_str_facts:\n",
    "        f=field\n",
    "        reviews_json_facts1=converting_to_str(f,reviews_json_facts1)\n",
    "    for field in full_review_to_str:\n",
    "        f=field\n",
    "        full_reviews=converting_to_str(f,full_reviews)\n",
    "    for field in d_to_str:\n",
    "        f=field\n",
    "        dates_dim1=converting_to_str(f,dates_dim1)\n",
    "    for field in d_to_bool:\n",
    "        f=field\n",
    "        dates_dim1=converting_to_boolean(f,dates_dim1)\n",
    "    for field in d_to_int:\n",
    "        f=field\n",
    "        dates_dim1=converting_to_int(f,dates_dim1)\n",
    "\n",
    "    #three convertions that are not part of the for loops:\n",
    "    users_json1=converting_to_list(\"elite\",users_json1)\n",
    "    users_json1=converting_to_date(\"yelping_since\",users_json1)\n",
    "    reviews_json_facts1=converting_to_date(\"date\",reviews_json_facts1) \n",
    "    dates_dim1=converting_to_date(\"full_date\",dates_dim1) \n",
    "    return business_json1,users_json1,reviews_json_facts1,full_reviews,dates_dim1\n",
    "\n",
    "#Calling the convertions function\n",
    "b,u,r,fv,d=types_convertion(business_json,users_json,reviews_json_facts,full_reviews_good,dates_dim)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displaying all converted tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b.display(1)\n",
    "u.display(1)\n",
    "r.display(1)\n",
    "d.display(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking all types of columns in all converted tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fields2 = b.fieldnames()\n",
    "for f in tqdm(fields2):\n",
    "    print f,'\\t', b.typecounter(f)\n",
    "    \n",
    "fields2 = u.fieldnames()\n",
    "for f in tqdm(fields2):\n",
    "    print f,'\\t', u.typecounter(f)\n",
    "    \n",
    "fields2 = r.fieldnames()\n",
    "for f in tqdm(fields2):\n",
    "    print f,'\\t', r.typecounter(f)\n",
    "    \n",
    "fields2 = d.fieldnames()\n",
    "for f in tqdm(fields2):\n",
    "    print f,'\\t', d.typecounter(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform (cont) - adding fields based on calculations we did before "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Adding fields to business table\n",
    "b = b.addfield('more_than_20',more_than_20)\n",
    "b = b.addfield('business_id_n',bussiness_id_generator)\n",
    "b = b.rename({'stars':'b_stars'})\n",
    "\n",
    "#Adding fields to users table\n",
    "u = u.addfield('active_years',active_years)\n",
    "u = u.addfield('elite_first_year',elite_first_year_func)\n",
    "u = u.addfield('time_to_elite',time_to_elite_func)\n",
    "u = u.addfield('is_elite_gold',is_elite_gold_func)\n",
    "u = u.addfield('is_elite_black',is_elite_black_func)\n",
    "u = u.addfield('elite_counter',elite_counter_func)\n",
    "u = u.addfield('active_years',active_years)\n",
    "u = u.addfield('elite_sequence',elite_sequence)\n",
    "u = u.addfield('weighted_score_for_reviews',weighted_score_for_reviews)\n",
    "u = u.addfield('yelp_celebrity',yelp_celebrity)\n",
    "u = u.addfield('loveliness_level',loveliness_level)\n",
    "u = u.addfield('active_user',active_user) \n",
    "u = u.addfield('funny_average',funny_average)\n",
    "u = u.addfield('cool_average',cool_average)\n",
    "u = u.addfield('fans_average',fans_average)\n",
    "u = u.addfield('user_id_n',user_id_generator)\n",
    "u = u.addfield('num_of_compliment',num_of_compliment_func)\n",
    "\n",
    "#converting user_id_n to int\n",
    "field='user_id_n'\n",
    "u=converting_to_int(field,u)\n",
    "\n",
    "#Adding fields to reviews table\n",
    "r = r.addfield('ratio_funny_reactios',ratio_funny_reactios)\n",
    "r = r.addfield('ratio_cool_reactios',ratio_cool_reactios)\n",
    "r = r.addfield('ratio_useful_reactios',ratio_useful_reactios)\n",
    "r = r.addfield('review_id_n',review_id_generator)\n",
    "r = r.rename({'stars':'r_stars'})\n",
    "\n",
    "#Join reviews and users tables in order to add more fields based on this join\n",
    "r_lj_u=etl.leftjoin(r,u, key='user_id')\n",
    "r_lj_u = r_lj_u.addfield('funny_average',funny_average)\n",
    "r_lj_u = r_lj_u.addfield('cool_average',cool_average)\n",
    "r_lj_u = r_lj_u.addfield('useful_average',useful_average)\n",
    "r_lj_u = r_lj_u.addfield('ratio_funny_review_user',ratio_funny_review_user)\n",
    "r_lj_u = r_lj_u.addfield('ratio_cool_review_user',ratio_cool_review_user)\n",
    "r_lj_u = r_lj_u.addfield('ratio_useful_review_user',ratio_useful_review_user)\n",
    "r_lj_u = r_lj_u.addfield('distance_stars_user',distance_stars_user)\n",
    "\n",
    "\n",
    "#Join reviews and business tables in order to add more fields based on this join\n",
    "r_lj_b=etl.leftjoin(r,b, key='business_id')\n",
    "r_lj_b=r_lj_b.addfield('distance_stars_business',distance_stars_business)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking joined tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r_lj_u.display(1)\n",
    "r_lj_b.display(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cutting required columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#creating our final tables for the dimentions - users and business\n",
    "users_dim=u.cut(['user_id_n','user_id','name','useful','funny','cool','weighted_score_for_reviews','fans','yelp_celebrity','loveliness_level','average_stars','yelping_since','compliment_photos','compliment_list','compliment_funny','compliment_plain','compliment_note','compliment_writer','compliment_cute','review_count','compliment_more','compliment_hot','elite','compliment_profile','compliment_cool','active_years','elite_first_year','time_to_elite','is_elite_gold','is_elite_black','elite_sequence','active_user','funny_average','cool_average','fans_average','elite_counter','num_of_compliment'])\n",
    "business_dim=b.cut(['business_id_n','city', 'review_count', 'name', 'business_id','is_open', 'b_stars', 'address','more_than_20'])\n",
    "\n",
    "#creating our fact table\n",
    "temp_r_lj_u=r_lj_u.cut(['review_id_n','user_id_n','user_id','business_id','review_id','date','r_stars','funny','cool', 'useful','ratio_funny_review_user', 'ratio_cool_review_user', 'ratio_useful_review_user', 'distance_stars_user'])\n",
    "temp_r_lj_b=r_lj_b.cut([\"review_id\",'business_id_n',\"distance_stars_business\"])\n",
    "fact_table=etl.join(temp_r_lj_u,temp_r_lj_b, key='review_id')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text characterization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# list of stopwords adopted from nltk\n",
    "stopset = ['all', 'just', 'being', 'over', 'both', 'through', 'yourselves', 'its', 'before', 'o', 'hadn', 'herself', 'll', 'had', 'should', 'to', 'only', 'won', 'under', 'ours', 'has', 'do', 'them', 'his', 'very', 'they', 'not', 'during', 'now', 'him', 'nor', 'd', 'did', 'didn', 'this', 'she', 'each', 'further', 'where', 'few', 'because', 'doing', 'some', 'hasn', 'are', 'our', 'ourselves', 'out', 'what', 'for', 'while', 're', 'does', 'above', 'between', 'mustn', 't', 'be', 'we', 'who', 'were', 'here', 'shouldn', 'hers', 'by', 'on', 'about', 'couldn', 'of', 'against', 's', 'isn', 'or', 'own', 'into', 'yourself', 'down', 'mightn', 'wasn', 'your', 'from', 'her', 'their', 'aren', 'there', 'been', 'whom', 'too', 'wouldn', 'themselves', 'weren', 'was', 'until', 'more', 'himself', 'that', 'but', 'don', 'with', 'than', 'those', 'he', 'me', 'myself', 'ma', 'these', 'up', 'will', 'below', 'ain', 'can', 'theirs', 'my', 'and', 've', 'then', 'is', 'am', 'it', 'doesn', 'an', 'as', 'itself', 'at', 'have', 'in', 'any', 'if', 'again', 'no', 'when', 'same', 'how', 'other', 'which', 'you', 'shan', 'needn', 'haven', 'after', 'most', 'such', 'why', 'a', 'off', 'i', 'm', 'yours', 'so', 'y', 'the', 'having', 'once']\n",
    "\n",
    "def word_feats(words):\n",
    "    return dict([(word, True) for word in words if word not in stopset])\n",
    "\n",
    "def save_classifier(classifier):\n",
    "   f = open('trained_classifier.pickle', 'wb')\n",
    "   pickle.dump(classifier, f, -1)\n",
    "   f.close()\n",
    "\n",
    "def load_classifier():\n",
    "   f = open('trained_classifier.pickle', 'rb')\n",
    "   classifier = pickle.load(f)\n",
    "   f.close()\n",
    "   return classifier\n",
    "\n",
    "#training the classifier to be able to identify the text\n",
    "def train_new_classifier():\n",
    "    '''\n",
    "    create a Naive Bayes Classifier based on movie reviews corpus\n",
    "    :return: \n",
    "    NaiveBayesClassifier\n",
    "    '''\n",
    "    negids = movie_reviews.fileids('neg')\n",
    "    posids = movie_reviews.fileids('pos')\n",
    "\n",
    "    negfeats = [(word_feats(movie_reviews.words(fileids=[f])), 'neg') for f in negids]\n",
    "    posfeats = [(word_feats(movie_reviews.words(fileids=[f])), 'pos') for f in posids]\n",
    "\n",
    "    trainfeats = negfeats + posfeats\n",
    "    testfeats = negfeats + posfeats\n",
    "    \n",
    "    classifier = NaiveBayesClassifier.train(trainfeats)\n",
    "    save_classifier(classifier)\n",
    "    return classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Checks if the classifier file exists in the same folder. if not, it creates one (may take some time)\n",
    "if os.path.exists('trained_classifier.pickle'):\n",
    "    classifier=load_classifier()\n",
    "else:\n",
    "    classifier=train_new_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify(d):\n",
    "    if debug: #if debug == True --> it will return 0,0,0 (In order to work quickly)\n",
    "        return 0,0,0\n",
    "    #\n",
    "    # if debug == False --> it will calculate all reviews' texts (may take a lot of time!)\n",
    "    #\n",
    "    if d==None:\n",
    "        return d,'na',0\n",
    "    a=classifier.prob_classify(word_feats(d))._prob_dict\n",
    "    sentiment=classifier.classify(word_feats(d))\n",
    "    magnitude=abs(float(a[sentiment])/(abs(a['pos'])+abs(a['neg'])))\n",
    "    return d,sentiment,magnitude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joining tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Creating our final users table (including date id)\n",
    "u_lj_dates=etl.leftjoin (users_dim,d,lkey='yelping_since',rkey='full_date')\n",
    "users_dim=u_lj_dates.cut(['user_id_n','user_id','name','useful','funny','cool','weighted_score_for_reviews','fans','yelp_celebrity','loveliness_level','average_stars','date_id','compliment_photos','compliment_list','compliment_funny','compliment_plain','compliment_note','compliment_writer','compliment_cute','review_count','compliment_more','compliment_hot','elite','compliment_profile','compliment_cool','active_years','elite_first_year','time_to_elite','is_elite_gold','is_elite_black','elite_sequence','active_user','funny_average','cool_average','fans_average','elite_counter','num_of_compliment'])\n",
    "users_dim = users_dim.rename({'date_id':'yelping_since(date_id)'})\n",
    "\n",
    "####################\n",
    "\n",
    "fv = fv.addfield('sentimemt',sentimemt_func)\n",
    "fv = fv.addfield('magnitude',folaritey_func)\n",
    "fv = fv.addfield('num_of_words_in_review',num_of_words_in_review_func)\n",
    "fv2= fv.cut(['review_id','magnitude','sentimemt','num_of_words_in_review'])\n",
    "\n",
    "#Creating our final fact table (including date id and text charictrization fields - sentiment, magnitude and num of words in a review)\n",
    "fact_lj_fv1=etl.join(fact_table,fv2,key='review_id')\n",
    "r_lj_dates_dim=etl.leftjoin(fact_lj_fv1,d, lkey='date',rkey='full_date')\n",
    "fact_table1=r_lj_dates_dim.cut(['review_id_n','user_id','user_id_n','business_id','review_id','date_id','r_stars','funny','cool','useful','ratio_funny_review_user','ratio_cool_review_user','ratio_useful_review_user','distance_stars_user','business_id_n','distance_stars_business','magnitude','sentimemt','num_of_words_in_review'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Last convertion in fact table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fact_table1=converting_to_float(\"magnitude\",fact_table1)\n",
    "fact_table1=converting_to_int(\"num_of_words_in_review\",fact_table1)\n",
    "fact_table1=converting_to_str(\"sentimemt\",fact_table1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Displaying final tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "business_dim.display(6)\n",
    "users_dim.display(6)\n",
    "fact_table.display(6)\n",
    "d.display(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecting to DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#con = mdb.connect(host = 'yelpdb.db.14017742.hostedresource.com', user = 'yelpdb', passwd = 'Sha!ardez1') \n",
    "con = mdb.connect(host = 'localhost', user = 'root', passwd = 'root')\n",
    "cursor = con.cursor()\n",
    "cursor.execute(\"SHOW DATABASES\") # running SQL\n",
    "#cursor.execute('DROP SCHEMA IF EXISTS shai1')\n",
    "cursor.execute('CREATE SCHEMA IF NOT EXISTS local_db')\n",
    "cursor.execute(\"USE local_db\")\n",
    "cursor.execute('SET SQL_MODE=ANSI_QUOTES')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading tables to DB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fact table (based on reviews table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fact_table1.todb(cursor,'fact_table',schema='local_db',create='True')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Business"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "business_dim.todb(cursor,'business',schema='local_db',create='True')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def change_format(file1,file2): # changing format of csv file in order to load properly to MYsqlDB\n",
    " #change from given dialect to standart\n",
    " ifile = open(file1, \"rb\")\n",
    " dialect = csv.Sniffer().sniff(ifile.read(1024))\n",
    " ifile.seek(0) #go back to start\n",
    " reader = csv.reader(ifile, dialect)\n",
    " ofile = open(file2, \"wb\")\n",
    " writer = csv.writer(ofile)\n",
    " writer.writerows(reader)\n",
    " ifile.close()\n",
    " ofile.close()\n",
    "\n",
    "users_dim.tocsv('users_dim.csv')\n",
    "change_format('users_dim.csv','users_dim_good.csv')\n",
    "users_dim=etl.fromcsv('users_dim_good.csv')\n",
    "users_dim.todb(cursor,'users',schema='local_db',create='True')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d.todb(cursor,'dates',schema='local_db',create='True')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sql configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#PRIMARY KEYS\n",
    "cursor.execute(\"ALTER TABLE fact_table ADD PRIMARY KEY (review_id_n);\")\n",
    "cursor.execute(\"ALTER TABLE dates ADD PRIMARY KEY (date_id);\")\n",
    "cursor.execute(\"ALTER TABLE users ADD PRIMARY KEY (user_id_n);\")\n",
    "cursor.execute(\"ALTER TABLE business ADD PRIMARY KEY (business_id_n);\")\n",
    "#FOREIGN KEYS\n",
    "cursor.execute(\"ALTER TABLE fact_table ADD FOREIGN KEY (date_id) REFERENCES dates(date_id);\")\n",
    "cursor.execute(\"ALTER TABLE fact_table ADD FOREIGN KEY (business_id_n) REFERENCES business(business_id_n);\")\n",
    "cursor.execute(\"ALTER TABLE fact_table ADD FOREIGN KEY (user_id_n) REFERENCES users(user_id_n);\")\n",
    "\n",
    "cursor.commit()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
